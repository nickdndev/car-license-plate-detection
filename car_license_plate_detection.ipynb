{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "from  detection_dataset import DetectionDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision import transforms\n",
    "\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "TRAIN_SIZE = 0.9\n",
    "BATCH_SIZE = 2\n",
    "BATCH_SIZE_OCR = 16\n",
    "DETECTOR_MODEL_PATH = 'detector.pt'\n",
    "OCR_MODEL_PATH = 'ocr.pt'\n",
    "\n",
    "all_marks = load_json(os.path.join(DATA_PATH, 'train.json'))[:50]\n",
    "test_start = int(TRAIN_SIZE * len(all_marks))\n",
    "train_marks = all_marks[:test_start]\n",
    "val_marks = all_marks[test_start:]\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detector_model():\n",
    "    \n",
    "    model = models.detection.maskrcnn_resnet50_fpn(\n",
    "        pretrained=True, \n",
    "        pretrained_backbone=True,\n",
    "        progress=True, \n",
    "        num_classes=91, \n",
    "    )\n",
    "\n",
    "    num_classes = 2\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.roi_heads.box_predictor = box_predictor\n",
    "    \n",
    "    mask_predictor = MaskRCNNPredictor(256, 256, num_classes)\n",
    "    model.roi_heads.mask_predictor = mask_predictor\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    for param in model.backbone.fpn.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    for param in model.rpn.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    for param in model.roi_heads.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = DetectionDataset(\n",
    "    marks=train_marks, \n",
    "    img_folder=DATA_PATH, \n",
    "    transforms=my_transforms\n",
    ")\n",
    "val_dataset = DetectionDataset(\n",
    "    marks=val_marks, \n",
    "    img_folder=DATA_PATH, \n",
    "    transforms=my_transforms\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn, \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "model = get_detector_model()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.5, verbose=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "\n",
    "    print_loss = []\n",
    "    for i, (images, targets) in tqdm.tqdm(enumerate(train_loader), leave=False, position=0, total=len(train_loader)):\n",
    "\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss_dict.values())\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print_loss.append(losses.item())\n",
    "        if (i + 1) % 20 == 0:\n",
    "            mean_loss = np.mean(print_loss)\n",
    "            print(f'Loss: {mean_loss:.7f}')\n",
    "            scheduler.step(mean_loss)\n",
    "            print_loss = [] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfa",
   "language": "python",
   "name": "alfa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
